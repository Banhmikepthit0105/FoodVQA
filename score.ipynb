{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pip install the necessary packages\n",
    "# !pip install nltk\n",
    "# !pip install rouge_score\n",
    "# !pip install openai\n",
    "# !pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Desktop\\22127432\\3-HK2\\TextMining\\FoodVQA\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import nltk\n",
    "import openai\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "input = r'test_data.csv'\n",
    "output_folder = r'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The sun rises the a east every morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The sun the in east every morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>popular a is programming language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>Python is a popular programming language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial intelligence is transforming the world</td>\n",
       "      <td>Artificial the is transforming world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>language is a popular programming Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial intelligence is transforming the world</td>\n",
       "      <td>transforming intelligence Artificial the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The rises Python every the east in morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>every sun rises in the east The morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The rises in every east over the morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0            The sun rises in the east every morning   \n",
       "1            The sun rises in the east every morning   \n",
       "2           Python is a popular programming language   \n",
       "3           Python is a popular programming language   \n",
       "4  Artificial intelligence is transforming the world   \n",
       "5           Python is a popular programming language   \n",
       "6  Artificial intelligence is transforming the world   \n",
       "7            The sun rises in the east every morning   \n",
       "8            The sun rises in the east every morning   \n",
       "9            The sun rises in the east every morning   \n",
       "\n",
       "                                 predicted_answer  \n",
       "0          The sun rises the a east every morning  \n",
       "1               The sun the in east every morning  \n",
       "2               popular a is programming language  \n",
       "3        Python is a popular programming language  \n",
       "4            Artificial the is transforming world  \n",
       "5        language is a popular programming Python  \n",
       "6  transforming intelligence Artificial the world  \n",
       "7      The rises Python every the east in morning  \n",
       "8         every sun rises in the east The morning  \n",
       "9        The rises in every east over the morning  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to pandas dataframe\n",
    "df = pd.read_csv(input)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluates the similarity between a predicted text and a reference text based on n-gram precision.\n",
    "How it is calculated:\n",
    "- Tokenize each sentence.\n",
    "- Count matching n-gram (usually 1-4).\n",
    "- Applies a penalty if `len(prediction)` < `len(answer)`.\n",
    "\n",
    "In this code:\n",
    "- BLEU-4 is used via `sentence_bleu` function from nltk: Each n-gram from 1 to 4 contributes equally to the final score.\n",
    "- `reference`: The target (goal) answers.\n",
    "- `hypothesis`: Generated answers.\n",
    "- `smoothie`: From nltk library to handle short sentences where high n-grams return no matches.\n",
    "\n",
    "The BLEU score is computed as:\n",
    "$$ BLEU = BP * exp(\\sum^{N}_{n=1}w_n log(p_n)) $$\n",
    "- BP: The penalty where:\n",
    "    + BP = 1 if $l_{pred} \\geq l_{ref}$\n",
    "    + BP = $e^{1 - \\frac{l_{ref}}{l_{pred}}}$ if $l_{pred} < l_{ref}$\n",
    "    + $l_X$: length of X\n",
    "- $p_n$: Count matching n-gram between predictions and reference.\n",
    "    + Clip (fit) the count to the maximum number of times each n-gram appears in the reference to avoid overcounting.\n",
    "    + $p_n$ = (sum of clipped n-gram counts) / (total n-grams in prediction).\n",
    "- $w_n$: Weight of each n-gram. In BLEU-4, each n-gram has equal weight of 0.25.\n",
    "- The exp function converts it back to a score of 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, hypothesis):\n",
    "    \"\"\"Calculate BLEU score for a single pair of sentences\"\"\"\n",
    "    ref_words = str(reference).strip().split()\n",
    "    hyp_words = str(hypothesis).strip().split()\n",
    "    \n",
    "    if not ref_words or not hyp_words:\n",
    "        return 0.0\n",
    "        \n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([ref_words], hyp_words, smoothing_function=smoothie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.3230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The sun rises the a east every morning</td>\n",
       "      <td>0.288540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The sun the in east every morning</td>\n",
       "      <td>0.228941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>popular a is programming language</td>\n",
       "      <td>0.124787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial intelligence is transforming the world</td>\n",
       "      <td>Artificial the is transforming world</td>\n",
       "      <td>0.124787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0            The sun rises in the east every morning   \n",
       "1            The sun rises in the east every morning   \n",
       "2           Python is a popular programming language   \n",
       "3           Python is a popular programming language   \n",
       "4  Artificial intelligence is transforming the world   \n",
       "\n",
       "                           predicted_answer  bleu_score  \n",
       "0    The sun rises the a east every morning    0.288540  \n",
       "1         The sun the in east every morning    0.228941  \n",
       "2         popular a is programming language    0.124787  \n",
       "3  Python is a popular programming language    1.000000  \n",
       "4      Artificial the is transforming world    0.124787  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the column named 'answer' and 'predicted_answer' if necessary\n",
    "if df is not None:\n",
    "    bleu_scores = [calculate_bleu(row['answer'], row['predicted_answer']) \n",
    "                  for _, row in df.iterrows()]\n",
    "    avg_bleu = np.mean(bleu_scores)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    bleu_results = pd.DataFrame({\n",
    "        'answer': df['answer'], # Reference - Change here\n",
    "        'predicted_answer': df['predicted_answer'], # Hypothesis - Change here\n",
    "        'bleu_score': bleu_scores\n",
    "    })\n",
    "    \n",
    "    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
    "    display(bleu_results.head())\n",
    "    bleu_results.to_csv(output_folder + 'bleu_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluates the similarity between a predicted text and a reference text based on recall of n-grams or longest common subsequences. How it works:\n",
    "- Tokenize each sentence into words.\n",
    "- Compute overlap between predictions and references:\n",
    "    + `ROUGE-1` measures overlap of unigrams based on recall.\n",
    "    + `ROUGE-2` measures overlap of bigrams.\n",
    "    + `ROUGE-L` measures the longest common subsequence (LCS).\n",
    "- Focuses on recall (fraction of reference content captured), reports F1 scores (harmonic mean of precision and recall).\n",
    "\n",
    "In this code:\n",
    "- `rouge_scorer` is used from the `rouge_score` library with stemming to normalize words.\n",
    "- Calculates three variants:\n",
    "    + rouge1: Unigram overlap.\n",
    "    + rouge2: Bigram overlap.\n",
    "    + rougeL: LCS-based similarity.\n",
    "- `reference`: The target (goal) answers.\n",
    "- `hypothesis`: Generated answers.\n",
    "\n",
    "The ROUGE score is computed as:\n",
    "\n",
    "ROUGE-N = (Number of overlapping N-grams) / (Total N-grams in reference)\n",
    "- This is the recall score. In practice, F1 is reported:\n",
    "F1 = 2*(Precision * Recall) / (Precision + Recall).\n",
    "    + Precision = (Number of overlapping N-grams) / (Total N-grams in reference)\n",
    "    + Recall = (Number of overlapping N-grams) / (Total N-grams in reference)\n",
    "\n",
    "ROUGE-L = LCS(reference, prediction) / (Total words in reference)\n",
    "- LCS: Length of LCS\n",
    "- F1 is also computed using precision (LCS length / prediction length) and recall (LCS length / reference length).\n",
    "- Scores range from 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(reference, hypothesis):\n",
    "    \"\"\"Calculate ROUGE scores for a single pair of sentences\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(str(reference), str(hypothesis))\n",
    "    return {\n",
    "        'rouge1': scores['rouge1'].fmeasure,\n",
    "        'rouge2': scores['rouge2'].fmeasure,\n",
    "        'rougeL': scores['rougeL'].fmeasure\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 Score: 0.9286\n",
      "Average ROUGE-2 Score: 0.4157\n",
      "Average ROUGE-L Score: 0.7160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The sun rises the a east every morning</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sun rises in the east every morning</td>\n",
       "      <td>The sun the in east every morning</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>popular a is programming language</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>Python is a popular programming language</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial intelligence is transforming the world</td>\n",
       "      <td>Artificial the is transforming world</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0            The sun rises in the east every morning   \n",
       "1            The sun rises in the east every morning   \n",
       "2           Python is a popular programming language   \n",
       "3           Python is a popular programming language   \n",
       "4  Artificial intelligence is transforming the world   \n",
       "\n",
       "                           predicted_answer    rouge1    rouge2    rougeL  \n",
       "0    The sun rises the a east every morning  0.875000  0.571429  0.875000  \n",
       "1         The sun the in east every morning  0.933333  0.461538  0.800000  \n",
       "2         popular a is programming language  0.909091  0.222222  0.545455  \n",
       "3  Python is a popular programming language  1.000000  1.000000  1.000000  \n",
       "4      Artificial the is transforming world  0.909091  0.222222  0.727273  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df is not None:\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        scores = calculate_rouge(row['answer'], row['predicted_answer']) # Change here\n",
    "        rouge1_scores.append(scores['rouge1'])\n",
    "        rouge2_scores.append(scores['rouge2'])\n",
    "        rougeL_scores.append(scores['rougeL'])\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_rouge1 = np.mean(rouge1_scores)\n",
    "    avg_rouge2 = np.mean(rouge2_scores)\n",
    "    avg_rougeL = np.mean(rougeL_scores)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    rouge_results = pd.DataFrame({\n",
    "        'answer': df['answer'], # Reference - Change here\n",
    "        'predicted_answer': df['predicted_answer'], # Hypothesis - Change here\n",
    "        'rouge1': rouge1_scores,\n",
    "        'rouge2': rouge2_scores,\n",
    "        'rougeL': rougeL_scores\n",
    "    })\n",
    "    \n",
    "    print(f\"Average ROUGE-1 Score: {avg_rouge1:.4f}\")\n",
    "    print(f\"Average ROUGE-2 Score: {avg_rouge2:.4f}\")\n",
    "    print(f\"Average ROUGE-L Score: {avg_rougeL:.4f}\")\n",
    "    display(rouge_results.head())\n",
    "    rouge_results.to_csv(output_folder + 'rouge_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gpt/ Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Api keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_api_key = \"apikey\" # Change here\n",
    "gemini_api_key = \"apikey\" # Change here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = gpt_api_key\n",
    "\n",
    "def get_gpt_score(reference, hypothesis):\n",
    "    \"\"\"Gets a GPT-based similarity score between reference and hypothesis.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert evaluator. Rate the similarity of the following hypothesis to the reference on a scale of 0 to 1.\n",
    "    \n",
    "    Reference: \"{reference}\"\n",
    "    Hypothesis: \"{hypothesis}\"\n",
    "    \n",
    "    Provide only the score as a number, nothing else.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\", # Change model here\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0  # Ensures consistent scoring\n",
    "    )\n",
    "    \n",
    "    score = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return float(score)  # Convert to float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    gpt_scores = []  # Store GPT scores\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        score = get_gpt_score(row['reference'], row['hypothesis'])  # Change column names as needed\n",
    "        gpt_scores.append(score)\n",
    "\n",
    "    # Calculate average GPT score\n",
    "    avg_gpt = np.mean(gpt_scores)\n",
    "\n",
    "    # Create results DataFrame\n",
    "    gpt_results = pd.DataFrame({\n",
    "        'reference': df['reference'],  # Change here\n",
    "        'hypothesis': df['hypothesis'],  # Change here\n",
    "        'gpt_score': gpt_scores\n",
    "    })\n",
    "    \n",
    "    print(f\"Average GPT Score: {avg_gpt:.4f}\")\n",
    "    display(gpt_results.head())\n",
    "    \n",
    "    gpt_results.to_csv(output_folder + 'gpt_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geminiscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"your-api-key\")\n",
    "\n",
    "def get_gemini_score(reference, hypothesis):\n",
    "    \"\"\"Gets a similarity score using Google's Gemini model.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert evaluator. Rate the similarity of the following hypothesis to the reference on a scale of 0 to 1.\n",
    "    \n",
    "    Reference: \"{reference}\"\n",
    "    Hypothesis: \"{hypothesis}\"\n",
    "    \n",
    "    Provide only the score as a number, nothing else.\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    score = response.text.strip()\n",
    "    return float(score)  # Convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    gemini_scores = []  # Store Gemini scores\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        score = get_gemini_score(row['reference'], row['hypothesis'])  # Change column names as needed\n",
    "        gemini_scores.append(score)\n",
    "\n",
    "    # Calculate average GeminiScore\n",
    "    avg_gemini = np.mean(gemini_scores)\n",
    "\n",
    "    # Create results DataFrame\n",
    "    gemini_results = pd.DataFrame({\n",
    "        'reference': df['reference'],  # Change here\n",
    "        'hypothesis': df['hypothesis'],  # Change here\n",
    "        'gemini_score': gemini_scores\n",
    "    })\n",
    "    \n",
    "    print(f\"Average Gemini Score: {avg_gemini:.4f}\")\n",
    "    display(gemini_results.head())\n",
    "    \n",
    "    gemini_results.to_csv(output_folder + 'gemini_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
